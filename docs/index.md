---
layout: default
title:  Home
---

![Mario](https://pypi-camo.freetls.fastly.net/198f06f6c66355bf8b78cae634e8155028948538/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f323138343436392f34303934393631332d37353432373333612d363833342d313165382d383935622d6365316363336166396462622e676966)       ![First Level](https://pypi-camo.freetls.fastly.net/c4717c633d3823dda390ebc21bac34b18e7c22c3/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f323138343436392f34303934383832302d33643135653563322d363833302d313165382d383164342d6563666166666565306131342e706e67) 


Source code: https://github.com/NathanVuong/Luigi-s-Mansion 

Reports:

- [Proposal](proposal.html)
- [Status](status.html)
- [Final](final.html)

---

Summary:

We're using OpenAIâ€™s Gym toolkit to implement a Double Q Learning Reinforcement Learning agent for Super Mario Bros. Our goal is to have Mario levels optimally based on different metrics/goals. The RL's Reward driving Mario's actions are based on Mario's x position, the time he takes, and a death penalty. 